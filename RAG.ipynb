{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\killme\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pwal9\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import fitz\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Bhagavad-gita As It Is\" by His Divine Grace A...</td>\n",
       "      <td>213</td>\n",
       "      <td>353.75</td>\n",
       "      <td>[0.0211626217, 0.0586190559, -0.0255278405, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Preface Originally I wrote Bhagavad-gétä As It...</td>\n",
       "      <td>266</td>\n",
       "      <td>449.50</td>\n",
       "      <td>[0.0681742355, 0.0634085238, -0.00446655322, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Some of them said that it is greatly fortunate...</td>\n",
       "      <td>24</td>\n",
       "      <td>36.75</td>\n",
       "      <td>[-0.00864421204, 0.097841993, -0.00656992709, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>original father of this movement is Lord Krish...</td>\n",
       "      <td>254</td>\n",
       "      <td>423.75</td>\n",
       "      <td>[0.0603890792, 0.0354894325, -0.0110460483, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Such unauthorized commentary upon Bhagavad-gét...</td>\n",
       "      <td>132</td>\n",
       "      <td>197.50</td>\n",
       "      <td>[0.0430899151, 0.0805046633, -0.0035992125, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>1048</td>\n",
       "      <td>50, Orizaba, Ver./ Tel.+52 (2717) 14825 PERU L...</td>\n",
       "      <td>18</td>\n",
       "      <td>28.25</td>\n",
       "      <td>[0.00698623061, -0.00365059334, -0.0355605371,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1049</td>\n",
       "      <td>◆ Lima — Schell 634 Miraﬂores/ Tel.+51 (014) 4...</td>\n",
       "      <td>143</td>\n",
       "      <td>217.75</td>\n",
       "      <td>[0.0495859608, 0.0401996486, -0.0269423407, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>1049</td>\n",
       "      <td>+593 (04) 308412 or 309420/  Fax: +564 302108/...</td>\n",
       "      <td>152</td>\n",
       "      <td>258.25</td>\n",
       "      <td>[0.0377525911, -0.0121238222, -0.0390545651, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>1049</td>\n",
       "      <td>+1 (809) 647-3165/  Fax: +1 (868) 647-6809/ E-...</td>\n",
       "      <td>87</td>\n",
       "      <td>153.25</td>\n",
       "      <td>[0.0195350163, 0.0349830948, -0.0256691165, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>1050</td>\n",
       "      <td>Colombia (Nueva Mathura) — Cruzero del Guali, ...</td>\n",
       "      <td>115</td>\n",
       "      <td>183.50</td>\n",
       "      <td>[0.00486746943, 0.0259503797, -0.0357118957, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1487 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      page_number                                     sentence_chunk  \\\n",
       "0               0  \"Bhagavad-gita As It Is\" by His Divine Grace A...   \n",
       "1               3  Preface Originally I wrote Bhagavad-gétä As It...   \n",
       "2               3  Some of them said that it is greatly fortunate...   \n",
       "3               4  original father of this movement is Lord Krish...   \n",
       "4               4  Such unauthorized commentary upon Bhagavad-gét...   \n",
       "...           ...                                                ...   \n",
       "1482         1048  50, Orizaba, Ver./ Tel.+52 (2717) 14825 PERU L...   \n",
       "1483         1049  ◆ Lima — Schell 634 Miraﬂores/ Tel.+51 (014) 4...   \n",
       "1484         1049  +593 (04) 308412 or 309420/  Fax: +564 302108/...   \n",
       "1485         1049  +1 (809) 647-3165/  Fax: +1 (868) 647-6809/ E-...   \n",
       "1486         1050  Colombia (Nueva Mathura) — Cruzero del Guali, ...   \n",
       "\n",
       "      chunk_word_count  chunk_token_count  \\\n",
       "0                  213             353.75   \n",
       "1                  266             449.50   \n",
       "2                   24              36.75   \n",
       "3                  254             423.75   \n",
       "4                  132             197.50   \n",
       "...                ...                ...   \n",
       "1482                18              28.25   \n",
       "1483               143             217.75   \n",
       "1484               152             258.25   \n",
       "1485                87             153.25   \n",
       "1486               115             183.50   \n",
       "\n",
       "                                              embedding  \n",
       "0     [0.0211626217, 0.0586190559, -0.0255278405, -0...  \n",
       "1     [0.0681742355, 0.0634085238, -0.00446655322, 0...  \n",
       "2     [-0.00864421204, 0.097841993, -0.00656992709, ...  \n",
       "3     [0.0603890792, 0.0354894325, -0.0110460483, 0....  \n",
       "4     [0.0430899151, 0.0805046633, -0.0035992125, 0....  \n",
       "...                                                 ...  \n",
       "1482  [0.00698623061, -0.00365059334, -0.0355605371,...  \n",
       "1483  [0.0495859608, 0.0401996486, -0.0269423407, 0....  \n",
       "1484  [0.0377525911, -0.0121238222, -0.0390545651, 0...  \n",
       "1485  [0.0195350163, 0.0349830948, -0.0256691165, 0....  \n",
       "1486  [0.00486746943, 0.0259503797, -0.0357118957, 0...  \n",
       "\n",
       "[1487 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "embsdf = pd.read_csv(\"chunks_and_embs_df.csv\")\n",
    "# embsdf.head()\n",
    "\n",
    "embsdf[\"embedding\"] = embsdf[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "pac = embsdf.to_dict(orient=\"records\")\n",
    "\n",
    "embeddings = torch.tensor(np.stack(embsdf[\"embedding\"].tolist(), axis=0), dtype=torch.float32).to(device=device)\n",
    "\n",
    "embsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.0211626217, 0.0586190559, -0.0255278405, -0...\n",
       "1       [0.0681742355, 0.0634085238, -0.00446655322, 0...\n",
       "2       [-0.00864421204, 0.097841993, -0.00656992709, ...\n",
       "3       [0.0603890792, 0.0354894325, -0.0110460483, 0....\n",
       "4       [0.0430899151, 0.0805046633, -0.0035992125, 0....\n",
       "                              ...                        \n",
       "1482    [0.00698623061, -0.00365059334, -0.0355605371,...\n",
       "1483    [0.0495859608, 0.0401996486, -0.0269423407, 0....\n",
       "1484    [0.0377525911, -0.0121238222, -0.0390545651, 0...\n",
       "1485    [0.0195350163, 0.0349830948, -0.0256691165, 0....\n",
       "1486    [0.00486746943, 0.0259503797, -0.0357118957, 0...\n",
       "Name: embedding, Length: 1487, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embsdf[\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1487, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\killme\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path='all-mpnet-base-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query : who was arjuna talking to\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.7093], device='cuda:0'),\n",
       "indices=tensor([152], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who was arjuna talking to\"\n",
    "print(f\"Query : {query}\")\n",
    "\n",
    "#embed\n",
    "\n",
    "\n",
    "query_emb = embedding_model.encode(query, convert_to_tensor=True).to(\"cuda\")\n",
    "\n",
    "dot_scores = util.dot_score(a=query_emb, b=embeddings)[0]\n",
    "\n",
    "top_reults = torch.topk(dot_scores, k=1)\n",
    "top_reults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def func(query:str, model, embeddings: torch.tensor) -> str:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He wants to stop friendly talks.Talks between the master and the disciple are serious, and now Arjuna wants to talk very seriously before the recognized spiritual master.Krishna is therefore the original spiritual master of the science of Bhagavad-gétä, and Arjuna is the first disciple for understanding the Gétä.How Arjuna understands the Bhagavad-gétä is stated in the Gétä itself.And yet foolish mundane scholars explain that one need not submit to Krishna as a person, but to “the unborn within Krishna.”There is no difference between Krishna’s within and without.And one who has no sense of this understanding is the greatest fool in trying to understand Bhagavad-gétä.TEXT 8 Na ih Pa[PaXYaaiMa MaMaaPaNauÛa‚ ÛC^aek-MauC^aez<aiMaiNd]Yaa<aaMa( ) AvaPYa >aUMaavSaPaÒMa*Ö&'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pacc = pac[top_reults.indices[0]]\n",
    "pacc[\"sentence_chunk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import textwrap\n",
    "\n",
    "# def wrapped(text, wrap_length=10):\n",
    "#     wrapped_Text = textwrap.fill(text, wrap_length)\n",
    "#     print(wrapped_Text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who was arjuna talking to\n",
      "\n",
      "tensor(0.7093, device='cuda:0')\n",
      "He wants to stop friendly talks.Talks between the master and the disciple are serious, and now Arjuna wants to talk very seriously before the recognized spiritual master.Krishna is therefore the original spiritual master of the science of Bhagavad-gétä, and Arjuna is the first disciple for understanding the Gétä.How Arjuna understands the Bhagavad-gétä is stated in the Gétä itself.And yet foolish mundane scholars explain that one need not submit to Krishna as a person, but to “the unborn within Krishna.”There is no difference between Krishna’s within and without.And one who has no sense of this understanding is the greatest fool in trying to understand Bhagavad-gétä.TEXT 8 Na ih Pa[PaXYaaiMa MaMaaPaNauÛa‚ ÛC^aek-MauC^aez<aiMaiNd]Yaa<aaMa( ) AvaPYa >aUMaavSaPaÒMa*Ö&\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query)\n",
    "print()\n",
    "for score, idx in zip(top_reults[0], top_reults[1]):\n",
    "    print(score)\n",
    "    print(pac[idx][\"sentence_chunk\"])\n",
    "    # print(f\"page no: {pac[idx][\"page_number\"]}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1163e-02,  5.8619e-02, -2.5528e-02, -5.9816e-03, -2.7692e-02,\n",
       "         1.8454e-02, -6.8008e-02,  1.3618e-02,  1.3084e-02,  6.9089e-03,\n",
       "         3.0247e-02, -1.6177e-02, -1.0645e-02, -2.0372e-02,  2.1421e-02,\n",
       "        -9.4767e-02,  1.7214e-02,  2.5570e-02, -1.1311e-02,  3.9779e-02,\n",
       "        -8.8459e-03, -2.7681e-03, -1.4302e-02,  1.7964e-02,  6.1292e-03,\n",
       "        -3.6292e-02,  3.0513e-02, -1.6677e-02, -2.0449e-02, -6.2248e-02,\n",
       "        -3.1691e-02,  5.3905e-03,  5.9277e-03,  5.8910e-02,  2.7739e-06,\n",
       "        -4.3372e-02, -4.2412e-03, -2.1236e-02, -3.4211e-02,  9.5382e-04,\n",
       "        -2.1264e-02,  4.9878e-02,  4.0554e-02, -2.2962e-02, -2.0445e-02,\n",
       "         9.0386e-02, -8.8574e-03,  6.5329e-02, -9.5708e-03,  4.7935e-02,\n",
       "        -3.7647e-03, -1.1760e-01,  4.1330e-03, -3.5087e-02,  2.4020e-02,\n",
       "         4.2913e-02, -3.1640e-02,  5.3709e-02,  1.4993e-02,  4.2173e-02,\n",
       "        -4.8077e-02, -1.4930e-02, -1.1748e-02,  2.1585e-02,  6.1268e-02,\n",
       "         3.8645e-02,  3.3878e-02,  2.0331e-02,  5.5787e-02,  8.6404e-03,\n",
       "         3.0183e-02, -4.0546e-02,  3.1441e-02,  3.8449e-02, -1.4002e-02,\n",
       "        -3.6303e-02,  1.3522e-03,  5.0740e-02, -1.6619e-02,  2.9743e-02,\n",
       "         3.6356e-02,  4.0628e-02, -5.6609e-02, -1.1010e-02,  7.4709e-02,\n",
       "        -8.5285e-03, -1.3820e-02,  3.2598e-03, -6.3416e-02, -7.2002e-03,\n",
       "        -8.4212e-02, -5.7362e-02, -5.6653e-02, -2.4288e-02,  2.5559e-02,\n",
       "         1.8362e-02, -1.3387e-02, -3.1854e-02, -1.5082e-02, -1.8622e-02,\n",
       "        -3.7275e-02,  5.1529e-02, -1.7929e-02,  3.9361e-03,  5.5597e-02,\n",
       "         5.0899e-02, -1.5549e-03,  6.1430e-02,  8.0309e-04,  1.0037e-01,\n",
       "         3.5089e-02,  1.4218e-02,  2.1977e-02,  1.7315e-02, -1.5879e-02,\n",
       "         1.0639e-02, -1.0928e-01, -3.3880e-02,  4.3806e-02, -2.6735e-02,\n",
       "        -3.3448e-02, -1.5727e-02, -9.2965e-03, -2.0793e-02,  2.3883e-02,\n",
       "        -5.9147e-02, -1.5081e-02, -2.8524e-02, -2.7142e-02, -2.6865e-02,\n",
       "         1.1526e-02,  1.6813e-02, -2.1176e-02,  4.2080e-02, -3.3887e-02,\n",
       "        -5.2577e-02,  2.3600e-02, -5.7444e-03, -7.3491e-02,  4.8123e-03,\n",
       "        -2.7055e-02, -1.3319e-02,  1.2003e-02,  3.3510e-02,  7.1840e-02,\n",
       "        -2.7092e-02,  1.2597e-02, -6.0561e-03, -1.9629e-02, -2.4252e-03,\n",
       "         7.8885e-03,  3.2458e-02, -6.7640e-03,  5.3835e-03,  3.7239e-02,\n",
       "         4.2891e-02,  3.1587e-02,  8.1120e-03, -1.5415e-04,  1.6889e-02,\n",
       "         3.9918e-02,  1.6206e-02,  4.5297e-02, -2.1173e-02,  2.3603e-02,\n",
       "        -3.6355e-02,  6.7809e-03, -5.5312e-03, -2.7191e-03, -2.7510e-02,\n",
       "        -6.1608e-02, -1.0405e-02, -5.2413e-02,  6.5410e-02, -2.6282e-02,\n",
       "         4.7543e-02, -8.8326e-03,  1.1047e-01, -1.9245e-02,  2.4513e-02,\n",
       "         4.9155e-02,  5.0530e-02, -2.0460e-02,  3.9048e-02,  4.2053e-02,\n",
       "         2.5008e-03,  1.4095e-02, -3.7212e-02,  2.9289e-02,  5.4412e-03,\n",
       "         1.8858e-02,  2.8347e-02, -8.4828e-02, -1.9983e-02, -2.8857e-02,\n",
       "        -5.0988e-02,  2.2619e-02, -6.8800e-02,  6.6469e-02, -5.8512e-02,\n",
       "         2.0705e-02,  6.1504e-03,  1.2887e-01, -4.5885e-02, -4.8759e-03,\n",
       "         1.7363e-02,  9.5728e-02, -1.5671e-02,  5.8779e-02, -1.2814e-02,\n",
       "        -4.8074e-02,  7.3900e-02, -7.0488e-02, -1.6092e-03,  9.8061e-03,\n",
       "         1.9173e-02, -4.4632e-03, -4.0039e-03, -4.6121e-02,  1.4512e-02,\n",
       "         3.0125e-02,  4.0395e-02, -1.0604e-02, -1.9661e-02,  7.1781e-02,\n",
       "        -5.1801e-02,  3.4460e-03, -3.6230e-02,  8.3360e-02, -7.3211e-02,\n",
       "        -1.7601e-02, -6.7363e-03, -4.1143e-02,  1.2628e-02, -3.4432e-02,\n",
       "         1.9826e-02, -6.6585e-03,  9.0663e-02, -5.5305e-02, -5.6229e-02,\n",
       "         5.2786e-02,  4.1337e-03, -6.2782e-03, -1.0321e-03, -1.8370e-02,\n",
       "         3.9189e-02, -3.0533e-02,  1.9802e-02,  1.5095e-03,  1.7616e-02,\n",
       "         3.5607e-02, -6.0376e-04, -4.3232e-02, -1.3892e-03, -5.2390e-03,\n",
       "        -5.6359e-02, -5.4695e-02,  7.7675e-02,  1.8161e-02,  3.4171e-02,\n",
       "         4.6680e-02,  1.7448e-03,  1.2906e-02, -3.5361e-02,  1.7269e-02,\n",
       "        -4.9357e-02,  1.2317e-02, -7.9863e-02,  1.2678e-02, -2.5366e-02,\n",
       "         1.6870e-02,  8.1233e-03, -2.6996e-02, -1.6211e-02, -1.3617e-04,\n",
       "        -3.6870e-02,  6.9304e-02,  5.2713e-02, -9.5138e-03, -1.3704e-02,\n",
       "        -3.3855e-02,  1.5721e-02, -6.8199e-03,  1.7244e-02,  7.7737e-03,\n",
       "        -1.3427e-02,  6.1484e-02, -3.1725e-02,  3.5806e-02, -4.5817e-02,\n",
       "         3.0614e-03, -4.3933e-03,  9.4547e-03, -3.4729e-02, -1.4192e-02,\n",
       "         6.0956e-02, -5.6021e-03,  2.5910e-03,  4.5003e-02,  1.2168e-02,\n",
       "        -6.2214e-02, -3.7591e-02,  1.9195e-02, -3.9229e-02,  4.2334e-02,\n",
       "        -5.6952e-02,  2.5366e-02, -1.5535e-02, -1.5998e-02, -1.8766e-02,\n",
       "        -8.7662e-04, -2.5428e-02, -4.7990e-02,  4.4795e-02, -6.9432e-02,\n",
       "         4.4415e-02, -1.2916e-02, -3.3719e-02,  7.6890e-03,  2.6898e-02,\n",
       "        -1.7086e-02, -2.7706e-02, -4.3167e-02,  3.3162e-03, -4.5985e-03,\n",
       "         1.4067e-02,  7.6450e-02, -2.3773e-02,  1.5164e-03,  1.4777e-03,\n",
       "         1.9515e-02,  8.5712e-03, -3.5756e-03, -2.2163e-02,  1.7123e-02,\n",
       "        -8.8600e-03, -1.4070e-02, -3.2141e-02, -3.4146e-02,  1.5204e-02,\n",
       "        -3.7020e-02,  9.7021e-03,  1.7168e-02,  4.5762e-02,  5.4669e-03,\n",
       "        -1.3138e-03, -8.0759e-03,  3.2953e-02, -1.3672e-02, -3.5847e-02,\n",
       "         2.1865e-03, -6.6413e-02, -1.1114e-02,  2.9503e-02,  1.1498e-02,\n",
       "        -7.7237e-02,  7.5749e-03,  2.6869e-02, -5.4072e-04,  6.3912e-02,\n",
       "        -4.2819e-02,  4.2358e-02, -7.5440e-03,  1.9006e-02,  4.4876e-02,\n",
       "        -1.4841e-02,  2.0496e-02,  2.0348e-02, -4.5313e-02,  4.5181e-03,\n",
       "        -2.7931e-02,  5.0430e-02, -2.9049e-03, -1.1318e-02, -3.6123e-02,\n",
       "        -2.2498e-02,  2.9585e-02, -8.1192e-02, -5.3989e-02, -1.7276e-02,\n",
       "         9.3365e-03, -1.0318e-01,  3.4029e-02,  2.0822e-02, -1.6140e-02,\n",
       "         3.1229e-02, -5.8795e-03,  4.3545e-02,  6.9714e-02, -5.2862e-02,\n",
       "         5.1087e-02,  1.6375e-02, -2.4007e-02,  8.0255e-02, -5.3885e-02,\n",
       "        -5.5845e-03, -4.3730e-02,  1.3979e-02,  4.7923e-02,  6.2429e-02,\n",
       "         1.8598e-02,  2.8518e-02,  4.7967e-02,  2.1617e-02,  5.4125e-02,\n",
       "        -5.4765e-02,  6.4096e-03, -1.2188e-02, -3.1001e-02, -1.9966e-02,\n",
       "         3.2074e-03, -5.0403e-02, -5.5792e-02,  5.1614e-02,  1.3392e-02,\n",
       "         2.8082e-03, -1.2614e-02,  1.2338e-06, -1.0928e-02,  1.9761e-02,\n",
       "         2.2233e-03,  7.3582e-02,  4.6017e-03,  3.0348e-02, -2.7529e-03,\n",
       "        -2.8478e-03, -2.0337e-02,  2.7111e-02, -3.5061e-02, -9.6565e-03,\n",
       "         1.4051e-02,  1.9428e-02, -1.2421e-02,  5.3281e-02,  5.4464e-03,\n",
       "        -6.6570e-02, -2.0183e-03,  1.8624e-02, -3.5286e-02, -1.3245e-03,\n",
       "        -2.5251e-02, -8.0173e-02, -2.0909e-04,  4.7578e-02, -4.0222e-02,\n",
       "         4.1756e-03, -6.9522e-03,  3.0344e-02, -1.2740e-02, -5.4719e-02,\n",
       "         1.0229e-02, -1.5350e-02, -2.3693e-02,  1.6933e-02, -1.7708e-02,\n",
       "        -2.2690e-02, -3.8499e-02,  3.2743e-03,  4.8801e-02,  6.1887e-04,\n",
       "         4.9430e-02,  1.1821e-02,  1.0785e-02,  1.2637e-02,  7.8972e-03,\n",
       "         1.8563e-02, -4.0267e-02, -4.2552e-02,  8.8184e-02, -1.9742e-02,\n",
       "         4.0787e-02, -1.2267e-02, -4.1460e-03,  3.8847e-02, -1.9349e-03,\n",
       "        -3.3268e-02, -2.7105e-02,  2.2593e-02,  6.7206e-03,  2.4858e-02,\n",
       "         2.6627e-02, -1.1867e-02,  1.2966e-02,  2.1981e-04,  2.2990e-02,\n",
       "        -3.1609e-02,  1.3041e-03, -1.1939e-02, -2.9808e-02, -2.4508e-02,\n",
       "         6.0300e-02, -3.2543e-03, -1.4645e-02, -9.0463e-02,  8.8876e-03,\n",
       "         1.4643e-02, -1.4638e-02, -4.2101e-03, -4.6949e-03, -4.8049e-03,\n",
       "        -1.9772e-03,  2.3068e-02,  3.4939e-02, -3.9674e-02, -5.8651e-02,\n",
       "        -2.1225e-02, -2.2035e-02, -1.2826e-03,  3.1416e-02, -1.8390e-02,\n",
       "         2.7539e-02, -1.7057e-02, -4.6786e-03, -1.4910e-02, -2.1160e-02,\n",
       "        -5.1642e-03,  1.4035e-02,  5.0104e-02, -1.7394e-03,  1.9998e-02,\n",
       "        -5.9839e-03,  1.2146e-02,  5.8020e-02, -8.8584e-03,  3.6658e-02,\n",
       "        -8.0333e-03, -1.2580e-02, -8.4312e-03, -8.0324e-02,  8.7500e-03,\n",
       "        -5.8495e-02, -4.7400e-02, -1.7675e-02, -2.0331e-02, -2.3945e-02,\n",
       "        -6.6068e-02, -9.7005e-02,  3.5601e-02,  8.6905e-02,  5.7594e-02,\n",
       "        -2.4033e-02,  1.9543e-02,  3.0478e-02, -1.0636e-02,  6.4788e-02,\n",
       "         1.2683e-02,  2.2131e-02,  1.7694e-02, -5.7861e-03, -3.0045e-02,\n",
       "        -1.5826e-02,  8.7580e-03, -6.2819e-02, -8.7204e-03,  1.8977e-02,\n",
       "        -7.2551e-33, -2.9919e-02,  3.4143e-03,  2.8069e-02, -1.3137e-02,\n",
       "        -6.5937e-02, -1.8829e-02, -2.0206e-02, -1.9441e-02, -6.9942e-03,\n",
       "         2.1239e-02, -1.7470e-02, -1.2795e-02, -8.1740e-03, -9.7276e-03,\n",
       "         4.0305e-02, -2.8018e-03, -9.4539e-03, -2.8051e-02, -3.3426e-02,\n",
       "         4.6496e-02,  7.0932e-03, -2.8346e-02,  4.7168e-02, -4.9600e-02,\n",
       "         1.6172e-02, -1.3260e-02, -7.7647e-02, -3.8738e-02, -4.4561e-02,\n",
       "        -2.7765e-02, -5.7165e-02, -3.0262e-02,  1.8409e-02,  2.6920e-02,\n",
       "         1.6425e-03,  9.0540e-03,  4.3918e-02, -2.1633e-02, -2.2088e-03,\n",
       "         4.1284e-02, -5.4625e-02, -5.7867e-02, -6.7026e-02, -3.2239e-02,\n",
       "         3.8419e-02,  2.6907e-02, -1.9086e-02,  3.6057e-02, -5.6599e-02,\n",
       "         5.9707e-03,  8.4683e-03, -5.8768e-04, -1.3965e-02,  2.9915e-02,\n",
       "        -4.6729e-03,  4.5062e-02, -2.9552e-02,  1.0238e-02,  2.0512e-02,\n",
       "         3.6842e-03,  1.3048e-02,  1.1649e-02, -8.8558e-02, -3.7140e-02,\n",
       "         6.0805e-02, -2.1513e-02, -3.1136e-02, -3.9985e-02, -6.4432e-02,\n",
       "        -2.8885e-02, -2.8086e-02, -2.0709e-02, -3.2499e-02, -1.9718e-02,\n",
       "         2.8755e-04, -1.1434e-01,  1.0023e-02, -6.3004e-03, -8.0899e-03,\n",
       "         2.5822e-02, -1.7602e-02,  4.0957e-02, -1.7753e-02,  1.2199e-03,\n",
       "         5.8617e-02, -7.7526e-02, -3.1802e-03,  6.3926e-02,  3.1491e-02,\n",
       "         1.9387e-02,  1.2191e-02,  2.0245e-02,  2.1777e-02, -1.9710e-02,\n",
       "         2.7143e-02,  5.1222e-02,  8.5747e-03,  1.4752e-02,  6.1686e-02,\n",
       "        -5.5235e-02, -4.2495e-02, -5.6296e-02, -2.2143e-02,  4.3296e-02,\n",
       "         4.7595e-03, -9.5927e-03,  6.7063e-02, -6.3258e-02, -1.9048e-02,\n",
       "        -7.7006e-03, -3.5388e-03,  9.0600e-03,  3.1878e-02, -5.9142e-02,\n",
       "        -3.9904e-02,  2.9958e-02,  1.3173e-02,  1.4366e-03,  3.2812e-02,\n",
       "        -1.6171e-02, -3.4578e-03,  1.2759e-02,  4.8342e-02,  3.0213e-02,\n",
       "         4.2179e-02,  3.1370e-02,  3.8833e-02,  7.0428e-03,  7.4408e-03,\n",
       "        -1.9472e-02,  4.2548e-03, -1.7751e-02,  3.4649e-07, -2.9498e-02,\n",
       "        -6.9993e-02, -2.5476e-02, -3.5599e-02,  8.9414e-03,  9.9567e-03,\n",
       "        -1.0154e-02,  4.0445e-03,  3.1884e-03,  1.2540e-02,  4.6602e-02,\n",
       "         2.7108e-03, -1.6111e-02, -5.6216e-02,  1.3619e-02, -7.9326e-02,\n",
       "        -5.6324e-02, -4.1120e-02,  2.9013e-02,  8.0068e-03,  1.2610e-02,\n",
       "        -1.1624e-02,  3.0451e-02,  1.9924e-03, -1.5338e-02,  4.5496e-02,\n",
       "         2.0239e-02,  1.8233e-02,  4.1538e-02,  3.4668e-02,  1.2796e-02,\n",
       "         1.8769e-02, -4.6797e-02, -6.3536e-02, -2.0093e-03, -2.7571e-02,\n",
       "         5.6641e-02,  7.8693e-02, -4.4386e-03,  9.6200e-02, -2.4202e-02,\n",
       "         6.1436e-02,  5.1233e-03, -3.4196e-02,  3.4226e-02, -1.0702e-02,\n",
       "        -2.8075e-02,  2.4139e-02, -1.3708e-02, -4.1386e-03,  2.2566e-02,\n",
       "         3.9019e-02, -2.2591e-02,  1.0031e-02, -3.2503e-02, -1.0673e-02,\n",
       "        -2.8003e-03,  2.3298e-02,  3.5420e-02,  1.3720e-02, -3.7828e-02,\n",
       "        -2.8936e-03,  2.0961e-02,  6.8070e-02,  2.6284e-02, -5.2014e-04,\n",
       "        -1.8921e-02,  2.6701e-34,  1.7854e-02, -5.6672e-02,  3.5376e-02,\n",
       "         2.4398e-02,  1.0135e-03,  1.1850e-03,  3.2242e-02, -1.2555e-02,\n",
       "         1.6199e-02,  6.8633e-03, -1.8944e-02], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 13 15:56:43 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.81                 Driver Version: 560.81         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P8              3W /   43W |     625MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     16960      C   ...ta\\anaconda3\\envs\\killme\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMS :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:23<00:00,  5.96s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                         bnb_4bit_compute_dtype=torch.float16\n",
    "                                        )\n",
    "\n",
    "\n",
    "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
    "    attn_implementation = \"flash-attention-2\"\n",
    "\n",
    "else:\n",
    "    attn_implementation = \"sdpa\"\n",
    "\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
    "\n",
    "\n",
    "llmmodel = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id,\n",
    "                                                torch_dtype=torch.float16,\n",
    "                                                quantization_config=quantization_config,\n",
    "                                                # low_cpu_mem_usage=False,\n",
    "                                                attn_implementation=attn_implementation)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc(model:torch.nn.Module):\n",
    "    return sum([param.numel() for param in llmmodel.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4540600320"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc(llmmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Sep 13 15:57:24 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.81                 Driver Version: 560.81         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   44C    P8              2W /   55W |    6401MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     16960      C   ...ta\\anaconda3\\envs\\killme\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp = \"what was the name of divine conch of krishna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what was the name of divine conch of krishna<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# checkpoint = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint)  # You may want to use bfloat16 and/or move to GPU here\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": inp,\n",
    "    }\n",
    "    # {\"role\": \"user\", \"content\": inp},\n",
    " ]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True) #, return_tensors=\"pt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "c:\\ProgramData\\anaconda3\\envs\\killme\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:660: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[128000, 128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,\n",
       "           2696,     25,   6790,    220,   2366,     18,    198,  15724,   2696,\n",
       "             25,    220,   1627,  10263,    220,   2366,     19,    271, 128009,\n",
       "         128006,    882, 128007,    271,  12840,    574,    279,    836,    315,\n",
       "          30467,    390,    331,    315,  23975,    819,   3458, 128009, 128006,\n",
       "          78191, 128007,    271,     40,   2846,    539,   8010,    315,    904,\n",
       "           2038,    922,    264,    330,    614,    483,    390,    331,      1,\n",
       "           5938,    449,  80409,     13,   4452,     11,    279,    390,    331,\n",
       "          12811,    374,   3629,   5938,    449,  80409,    439,    264,   7891,\n",
       "            315,    813,  30467,   7899,    477,    813,   3717,    311,    279,\n",
       "          18435,     13, 128009]], device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs = llmmodel.generate(tokenized_chat, max_new_tokens=100) \n",
    "# print(tokenizer.decode(outputs[0]))\n",
    "\n",
    "inputid = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = llmmodel.generate(**inputid,\n",
    "                            max_new_tokens=256)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_resources(query: str,\n",
    "                                embeddings: torch.tensor,\n",
    "                                model: SentenceTransformer=embedding_model,\n",
    "                                n_resources_to_return: int=3,\n",
    "                                print_time: bool=True):\n",
    "    \"\"\"\n",
    "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed the query\n",
    "    query_embedding = model.encode(query, \n",
    "                                   convert_to_tensor=True) \n",
    "\n",
    "    # Get dot product scores on embeddings\n",
    "    # start_time = timer()\n",
    "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
    "    # end_time = timer()\n",
    "\n",
    "    # if print_time:\n",
    "        # print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "    scores, indices = torch.topk(input=dot_scores, \n",
    "                                 k=n_resources_to_return)\n",
    "\n",
    "    return scores, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_decoded = tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Jul 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nBased on the following context items, please answer the query.\\nGive yourself room to think by extracting relevant passages from the context before answering the query.\\nDon\\'t return the thinking, only return the answer.\\nMake sure your answers are as explanatory as possible.\\nUse the following examples as reference for the ideal answer style.\\nREMEMBER NEVER TO USE THE FOLLOWING SENTENCES IN YOUR OUTPUT, THEY ATE JUST THE FORMATS\\n\\nExample 1:\\nQuery: What are the fat-soluble vitamins?\\nAnswer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body\\'s fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\\n\\nExample 2:\\nQuery: What are the causes of type 2 diabetes?\\nAnswer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body\\'s cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\\n\\nExample 3:\\nQuery: What is the importance of hydration for physical performance?\\nAnswer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\\n\\nNow use the following context items to answer the user query:\\n- sa-rahasyaà tad-aìgaà ca gåhäëa gaditaà mayä “The knowledge of the self and Supreme Self is very confidential and mysterious, but such knowledge and specific realization can be understood if explained with their various aspects by the Lord Himself.”Bhagavad-gétä gives us that general and specific knowledge of the self.The living entities are parts and parcels of the Lord, and therefore they are simply meant to serve the Lord.This consciousness is called Krishna consciousness.So, from the very beginning of life one has to learn this Krishna consciousness, and thereby one may become fully Krishna conscious and act accordingly.Lust is only the perverted reflection of the love of God which is natural for every living entity.But if one is educated in Krishna consciousness from the very beginning, that natural love of God cannot deteriorate into lust.When love of God deteriorates into lust, it is very difficult to return to the normal condition.Nonetheless, Krishna consciousness is so powerful that even a late beginner can become a lover of God by following the regulative principles of devotional service.So, from any stage of life, or from the time of understanding its urgency, one can begin regulating the senses in Krishna consciousness, devotional service of the Lord, and turn the lust into love of Godhead—the highest perfectional stage of human life.TEXT 42 wiNd]Yaai<a Para<YaahuiriNd]Yae>Ya\" Par& MaNa\" ) MaNaSaSTau Para buiÖYaaeR buÖe\" ParTaSTau Sa\" )) 42 )) indriyäëi paräëy ähur indriyebhyaù paraà manaù manasas tu parä buddhir yo buddheù paratas tu saù SYNONYMS\\n- TRANSLATION The senses, the mind and the intelligence are the sitting places of this lust.Through them lust covers the real knowledge of the living entity and bewilders him.PURPORT The enemy has captured different strategic positions in the body of the conditioned soul, and therefore Lord Krishna is giving hints of those places, so that one who wants to conquer the enemy may know where he can be found.Mind is the center of all the activities of the senses, and thus when we hear about sense objects the mind generally becomes a reservoir of all ideas of sense gratification; and, as a result, the mind and the senses become the repositories of lust.Next, the intelligence department becomes the capital of such lustful propensities.Intelligence is the immediate next-door neighbor of the spirit soul.Lusty intelligence influences the spirit soul to acquire the false ego and identify itself with matter, and thus with the mind and senses.The spirit soul becomes addicted to enjoying the material senses and mistakes this as true happiness.This false identification of the spirit soul is very nicely explained in the Çrémad-Bhägavatam (10.84.13): yasyätma-buddhiù kuëape tri-dhätuke sva-dhéù kalaträdiñu bhauma ijya-dhéù yat-tértha-buddhiù salile na karhicij janeñv abhijïeñu sa eva go-kharaù “A human being who identifies this body made of three elements with his self, who considers the by-products of the body to be his kinsmen, who considers the land of birth worshipable, and who goes to the place of pilgrimage simply to take a bath rather than meet men of transcendental knowledge there, is to be considered like an ass or a cow.TEXT 41\\n- Therefore, lust and wrath, when they are employed in Krishna consciousness, become our friends instead of our enemies.TEXT 38 DaUMaeNaaiv]YaTae viöYaRQaadXaaeR Male/Na c )\\n\\nRelevant passages: <extract relevant passages from the context here>\\nUser query: tell me how did krishna advice people when it comes to lust, how to tackle it\\nAnswer:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatter(query:str, context_item: list[dict]) -> str:\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_item])\n",
    "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
    "Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
    "Don't return the thinking, only return the answer.\n",
    "Make sure your answers are as explanatory as possible.\n",
    "Use the following examples as reference for the ideal answer style.\n",
    "REMEMBER NEVER TO USE THE FOLLOWING SENTENCES IN YOUR OUTPUT, THEY ATE JUST THE FORMATS\n",
    "\\nExample 1:\n",
    "Query: What are the fat-soluble vitamins?\n",
    "Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and can be stored in the body's fatty tissue and liver for later use. Vitamin A is important for vision, immune function, and skin health. Vitamin D plays a critical role in calcium absorption and bone health. Vitamin E acts as an antioxidant, protecting cells from damage. Vitamin K is essential for blood clotting and bone metabolism.\n",
    "\\nExample 2:\n",
    "Query: What are the causes of type 2 diabetes?\n",
    "Answer: Type 2 diabetes is often associated with overnutrition, particularly the overconsumption of calories leading to obesity. Factors include a diet high in refined sugars and saturated fats, which can lead to insulin resistance, a condition where the body's cells do not respond effectively to insulin. Over time, the pancreas cannot produce enough insulin to manage blood sugar levels, resulting in type 2 diabetes. Additionally, excessive caloric intake without sufficient physical activity exacerbates the risk by promoting weight gain and fat accumulation, particularly around the abdomen, further contributing to insulin resistance.\n",
    "\\nExample 3:\n",
    "Query: What is the importance of hydration for physical performance?\n",
    "Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature, and ensuring the transport of nutrients and oxygen to cells. Adequate hydration is essential for optimal muscle function, endurance, and recovery. Dehydration can lead to decreased performance, fatigue, and increased risk of heat-related illnesses, such as heat stroke. Drinking sufficient water before, during, and after exercise helps ensure peak physical performance and recovery.\n",
    "\\nNow use the following context items to answer the user query:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    " \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "\n",
    "    # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt\n",
    "\n",
    "query = \"\"\n",
    "\n",
    "scores, indices = retrieve_relevant_resources(query=query, embeddings=embeddings)\n",
    "\n",
    "context_item = [pac[i] for i in indices]\n",
    "\n",
    "prompt = formatter(query=query, context_item=context_item)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: tell me how did krishna advice people when it comes to lust, how to tackle it\n",
      "RAG answer:\n",
      "<|begin_of_text|>Krishna advises that lust can be tackled by being educated in Krishna consciousness from the very beginning of life. This education enables one to understand the natural love of God and prevents it from deteriorating into lust. When one is educated in Krishna consciousness, lust can become a friend instead of an enemy, and can even be transformed into the love of Godhead, the highest perfectional stage of human life.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "inputid = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = llmmodel.generate(**inputid,\n",
    "                            temperature=0.7,\n",
    "                            do_sample=True,\n",
    "                            max_new_tokens=256)\n",
    "\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, \n",
    "        temperature=0.7,\n",
    "        max_new_tokens=512,\n",
    "        format_answer_text=True, \n",
    "        return_answer_only=True):\n",
    "    \"\"\"\n",
    "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get just the scores and indices of top related results\n",
    "    scores, indices = retrieve_relevant_resources(query=query,\n",
    "                                                  embeddings=embeddings)\n",
    "    \n",
    "    # Create a list of context items\n",
    "    context_items = [pac[i] for i in indices]\n",
    "\n",
    "    # Add score to context item\n",
    "    for i, item in enumerate(context_items):\n",
    "        item[\"score\"] = scores[i].cpu() # return score back to CPU \n",
    "        \n",
    "    # Format the prompt with context items\n",
    "    prompt = formatter(query=query,\n",
    "                              context_item=context_item)\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate an output of tokens\n",
    "    outputs = llmmodel.generate(**input_ids,\n",
    "                                 temperature=temperature,\n",
    "                                 do_sample=True,\n",
    "                                 max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # Turn the output tokens into text\n",
    "    output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "    if format_answer_text:\n",
    "        # Replace special tokens and unnecessary help message\n",
    "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
    "\n",
    "    # Only return the answer without the context items\n",
    "    if return_answer_only:\n",
    "        return output_text\n",
    "    \n",
    "    return output_text, context_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>The relevant passages are:\n",
      "\n",
      "\"Bhagavad-gétä gives us that general and specific knowledge of the self. The living entities are parts and parcels of the Lord, and therefore they are simply meant to serve the Lord. This consciousness is called Krishna consciousness.\"\n",
      "\n",
      "\"Bhagavad-gétä\" is mentioned here as the source of knowledge, and it is implied that Lord Krishna is the one who imparts this knowledge.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(rag(query=\"what did bhrahma say about krishna\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
